# 第十三章 精简指令集计算机

## KEY POINTS

1. RISC 产生的背景

2. RISC 机主要的三个特征：大寄存器组、精简的指令集，流水线优化

3. 大寄存器组中，如何处理局部变量。全局变量存放于何处？跟 cache 相比的优缺点

4. 编译器如何优化寄存器的使用

5. RISC 和 CISC 的区别、优缺点

6. RISC的流水线优化技术包含哪三种

> 易俊泉学长的原始笔记链接如下：
>
> [chapter13 精简指令集计算机](docs/课内笔记/大三上/计算机组成与结构/笔记/易俊泉/chapter13精简指令集计算机.md)

RISC：Reduced Instruction Set Computer，精简指令集计算机

CISC：Complex Instruction Set Computer，复杂指令集计算机

> 我感觉 RISC 要是改名叫 Simple Instruction Set Computer 估计更好记点……

复杂指令集不仅指每条指令内容复杂，还指指令数量很多。

### 什么是 RISC？

1. 指令长度固定，不允许指令长度扩展

   x86 等复杂指令集允许某个指令通过一些标志，声明自己的长度比通常指令更长、更复杂；RISC 不允许指令长度的扩展

2. 使用大量的通用寄存器、或使用编译器对有限寄存器的使用进行优化

   这是因为指令长度固定，因此 RISC 机的指令数更多；为了提高执行效率，RISC 使用更多的通用寄存器，以加速指令取操作数的过程；

   在无法增加寄存器时，编译器需要负责把程序中最常用的变量放在寄存器中，以实现最大程度的优化

3. 对流水线的执行进行了高度优化

   这一优化任务同样由编译器完成。



## 指令执行的特征

### CISC 机的历史

随着编程语言逐渐向高级发展，很多实现细节被隐藏了。

> 比如，Java 有垃圾回收，让程序员再也不用关注堆区内存管理了

因此，高级语言和机器指令集间的语义鸿沟越来越大，编译器也越来越复杂。CISC 想要简化编译器的编写难度，因此 CISC 不断增加各种复杂指令，可以实现各种组合操作，让编译器不必费劲优化指令。

后来，因为指令不断增加，CU 太难做了，CISC 开始研究高级语言指令的规律，比如指令的常见顺序是怎么样的，具体结果如下：

![image-20241106115057889](https://telegraph-image-5ms.pages.dev/file/BQACAgUAAyEGAASIfjD1AAM_Z6F5wvPOXb3b2x7CHykD5ffJOVAAAqYSAAK0lBBVzCE4VJgFwpI2BA.png)

可以看出，ASSIGN（赋值）指令的占比是最大的，LOOP（循环）指令的耗时和内存消耗都较大，CALL（调用）指令的内存开销很大。

RISC 关注这些开销最大的指令，并想办法优化这些内容。RISC 并不对所有指令进行优化。

指令执行关注的方面：执行的操作、所用的操作数、执行顺序

### 操作 operation

:one: 赋值语句在程序中出现的频率最高

> 数据传送非常频繁

:two: 条件语句出现的频率也较高

> 指令的顺序控制非常重要

:three: 过程调用/返回的操作耗时最多

> 但过程调用的深度一般不会很深

可以把过程调用参数放在寄存器中，防止频繁的弹栈压栈导致内存访问开销太大。

同样，将大量数据存放在寄存器中也可以减少赋值语句的开销。

### 操作数 operand

主要使用的是简单的标量变量，且其中很大比例又是局部标量变量

优化的主要方向应是对局部标量变量 **local variables** 进行快速的存储和访问

### 过程调用 | Procedure Calls

最耗时

其耗时取决于过程调用中使用参数及变量的个数和取决于嵌套的深度

每个过程调用所涉及数据传递的量并不大，绝大多数都是对局部变量的访问，大多数过程嵌套的深度不会很深

操作数的访问是符合局部性原理的

### 推论

让机器指令集更接近 HLL （高级程序语言，High-Level Language）效果并不好，通过优化最常用和最耗时的操作才能更好的支持 HLL 计算机高级语言。

:one: 使用大量寄存器

> 以避免对局部变量的访问需要访存

:two: 更为小心的设计指令流水线

> 专门处理转移

:three: 指令集设计应尽量简化或者说是精简，让 CU 的执行效率更高

所以使用RISC有其必要性。



下面具体介绍这三个推论是如何在 RISC 指令集中实现的。

## 大寄存器组的使用 large register file

> 千万别翻译成「大寄存器文件」，这边的 file=set（组），不是文件的意思。

**寄存器特点**

- 比主存和cache还快

- 由于个数更少，其地址比主存储器和 cache 更短

- 靠近 CPU

寄存器数量有限，应把最经常访问的数据放入寄存器，以尽量减小访存操作，提高指令执行速度

### 计算机中寄存器的分配

分配存在两种优化方式：软件优化和硬件优化。

#### 软件解决办法

依靠编译器分配寄存器

原则：将寄存器分配给那些在给定时间期内使用最多的变量

要求使用复杂的程序分析算法

#### 硬件解决办法

配置更多的寄存器

使得更多的变量保存在寄存器中

### 寄存器窗口

使用一大组寄存器应该能减少对存储器访问的需求，因此设计的任务就是更好地分配寄存器来实现这个目标

#### 寄存器中的局部变量

将局部标量变量存储在寄存器中，以减小内存访问；每次过程（函数）调用都会改变 “局部变量”

具体所指；原有过程的局部变量必须被送到存储器，以腾出寄存器空间供现有正在执行的过程的局部变量来使用

每次过程调用时

> 父过程的局部变量一般会压入栈
>
> 父过程给子过程的参数一般通过栈传递
>
> 子过程给父过程的结果一般通过栈返回

#### 寄存器窗口的使用

既然过程调用中的操作数压栈和弹栈需要最多的时间，我们就使用大量寄存器，存储所有过程调用中的变量，不用把它们压入栈，只需要切换不同窗口。

解决的方法是基于两个结论。

> 第一，一个典型的过程只使用少数传送参数和局部变量。第二，过程调用的深度仅限定在一个相对窄的范围内。
>
> 这两个结论说明，过程调用时，一般传递的参数的规模都不会太大。

为利用这些性质，使用多个小的寄存器组，每个小组指派给一个不同的过程。过程调用时自动地切换来使用**不同的但大小固定**的寄存器窗口，而不再在存储器保存寄存器内容。相邻过程的窗口是（部分）重叠的，以允许参数传递

![image-20211227085713193](https://raw.githubusercontent.com/yijunquan-afk/img-bed-1/main/img2/1695704526.png)

每个寄存器区域分为三个窗口：参数寄存器区，变量寄存器区和暂存寄存器区。父过程的暂存寄存器区和子过程的参数寄存器区是相同的物理寄存器组成的，因此子过程可以直接读取父过程传入的参数（放在暂存寄存器区的参数），不需要压栈弹栈。

每次只有一个寄存器窗口对用户可见，过程返回时自动切换回父过程使用的那组寄存器

#### 环形缓冲组织

进行调用时，将移动当前窗口指针以指示当前活动过程的寄存器窗口

如果所有窗口都在使用中，则会生成一个中断，并将**最早的窗口（嵌套中最远的那个窗口）保存到内存中**。

> 先移动 CWP(Current Window Pointer)，如果 CWP 和 SWP（Saved Window Pointer，指向第一个压入栈的窗口的首地址） 重叠，说明寄存器放满了，应当立刻发起一个中断，把 SWP 指向的内容压入栈中（保存到内存），移动 SWP，然后再向后移动 CWP。

N 个窗口的寄存器组仅能用于 N-1 个过程的直接调用。因为**不能让第 N 个寄存器的暂存区域和第 1 个寄存器参数域重叠**。

> 如果当前过程调用的嵌套超过了 N-1 层，就把第 0 层压入栈，再占用这部分寄存器，放入第 N 层的调用数据。

•Berkeley RISC，通常采用8个窗口，每个窗口16个寄存器

![image-20211227090013987](https://raw.githubusercontent.com/yijunquan-afk/img-bed-1/main/img2/1695704527.png)

一个过程完成调用后，CWP 逆时针移动一步，释放一个寄存器窗口。

### 全局变量

上面的寄存器窗口提供了很好的存储局部变量的方法，但是无法使用这种方法存储全局变量。

对于全局变量，可以通过如下两种方式存储：

一种方法时让编译器为声明的全局变量指派寄存器的地址，可以加速全局变量的访问速度

> 如果需要频繁访问的全局变量，效率较低

另一种的方法是给全**局变量单独分配一组寄存器**，专门放全局变量，供所有过程使用

全局变量寄存器在物理上独立于环形寄存器窗口，但和窗口寄存器统一编址。比如，大小为 6 的窗口，其编号只能在 0-5 内，全局变量寄存器可能占用 6 号位置且编号一直不变。

当全局变量的数目超过此寄存器组内寄存器的总数时，仍由编译器来决定哪些全局变量放在寄存器，哪些放回存储器

### 大寄存器组与cache的比较

大寄存器可以加速全局变量的访问，这很容易让我们想到 cache。所以，大寄存器组和 cache 哪个更好呢？

存储内容：

- 大寄存器组：存储 n-1 次调用的所有局部标量，大小固定，因此利用率可能比较低
- 缓存：存储最近使用的局部标量，可能夹杂一些并不会用到的数据。

:one: 基于窗口的寄存器更快，但缓存可以更有效地利用空间，寄存器由于大小固定，不能对动态变化的情况作出反应（比如一个函数返回值只用了两个寄存器，但是一个窗口包含四个寄存器，剩下的两个寄存器就没有被利用）

:two: 缓存可能会遭受另一种效率低下的问题:数据被读入块但是其中一些不会被使用

:three: 在寄存器组中，使用内存相对频繁，组关联cache会受到覆盖使用的变量的影响

:four: 寄存器组的地址较短，比缓存快（缓存仍然采用主存地址寻址，只不过它只用主存地址的一部分）

通常，寄存器窗口优于缓存。

## 基于编译器的寄存器优化

假定目标 RISC 机器是 MIPS 机器，上只有少量寄存器可用（如16~32个），这时优化寄存器的使用就是编译器的责任了。

高级语言编写的程序没有对寄存器的显式引用，程序中的变量一般是符号表示的。

> C 语言存在关键字 register，不过设置为寄存器的变量也不一定会被编译器放到寄存器；其他语言更是没有任何语法允许你把变量放到寄存器。

**编译器的目标**：**尽可能在寄存器中存储最多的操作数，并且减少装载和保存操作。**

<font color="\#145b7d">**如何优化**</font>

1. 先给所有变量分配一个符号寄存器（虚拟的寄存器），使用时间上不重叠的符号寄存器可共享同一物理寄存器

2. 如果某一时段物理寄存器用尽，则某些变量仍需放回主存

> 编译器还需要对寄存器变量进行分析，来决定哪些变量放回存储器，使得程序能尽量减少访存次数

优化任务的本质——判定在程序的任何给定时间点，哪些的量应指派给寄存器，最多能放入多少变量到寄存器——**图着色法**

### 图着色法🎨

**图着色**：对于由结点和边组成的给定图，为节点指定颜色，并且使相邻节点不同色，而且要使颜色数最少。

<font color="red">**对于编译问题**</font>：图的节点就是符号寄存器

1. 若两个符号寄存器同一时间都存在，则在相应的两个节点间连接一条边来表示相关。

2. 尝试用 n 种颜色给图上色，n 是指真实寄存器的数目。
3. **如果无法成功上色，那么这些不能上色的节点必须放入存储器**中（说明寄存器放不下这么多变量）

> 左侧图片显示了 A- F 六个变量随时间的使用情况，纵轴表示时间流逝。可以看出，A 和 D 变量在时间上并不重叠使用，因此两者理论上可以放入同一寄存器；B 和 D 在时间轴上重叠，因此二者不能放入同一寄存器，在右图中，需要在 B- D 间画上一条边。

![image-20211119103322765](https://raw.githubusercontent.com/yijunquan-afk/img-bed-1/main/img2/1695704531.png)

上图中染色后无法染色的点为 F，即变量 F 必须放入主存中，无法放入寄存器。

染色相同的点分时存放在不同寄存器中。

## 精简指令集架构

### 为什么选择 CISC

使用 CISC 的理由：简化编译器、可生成更小更快的程序

但事实上，编译器并不总能生成更小的程序。

### RISC 特征

:one:  每个机器周期一条机器指令

:two: 大多数操作应该是寄存器到寄存器的（即操作数和结果都放在寄存器中）

:three: 简单的寻址方式

:four: 简单的指令格式

:five: 更多的编译时间

### RISC vs CISC

**什么是RISC:question:**

> Reduced Instruction Set Computers，即精简指令集计算机
>
> <font color="red">**主要特征有**</font>
>
> > 通过大量的通用寄存器和（或）使用编译器技术来优化寄存器的使用
> >
> > 一个有限且简单的指令集
> >
> > 强调指令流水的优化

**什么是CISC**

> 复杂指令集计算机
>
> > 提供更大的指令集
> >
> > 提供更多的寻址方式
> >
> > 直接用硬件去实现的各种高级语言（HLL）句

**二者比较**

> RISC比CISC更能提高计算机的运算速度
>
> RISC比CISC更便于设计，可降低成本，提高可靠性
>
> RISC更有效支持HLL
>
> RISC在实现特殊功能时，效率比较低，可以通过流水线优化改进，CISC处理特定功能时效率比较高

其实很难比较，大多数商用机都是混合架构



## RISC 流水线

RISC 中，大多数指令是寄存器到寄存器的，不需要访问主存。指令周期有两个阶段：

> I：指令获取（取指）
>
> E：指令执行（执行）

对于存在装载和保存操作的指令，需要三个阶段

> I：取指令
>
> E：执行
>
> D：存储

即访问寄存器的指令需要两拍完成，需要访问内存的指令使用三拍完成。

下图展示了五条指令顺序执行，采用两段流水线、三段流水线和四段流水线花费的时间。流水线采用延迟转移策略（遇到转移指令时，插入 NOOP 指令空过时拍，不执行后面的指令，直到转移指令执行完毕）

**两段流水线**：

两端流水线中，只有两条指令的 I 和 E（取指令和执行）可以同时执行，D（存储）和任何指令都不能同时执行。

D 被视为 E 阶段的一部分。

因此，有时 I、E 之间需要空过一拍，等上一个指令的 D 部分完成后，再执行 E 部分。

**三段流水线**

三段流水线中，不同指令的 I、E、D 都可以并行执行。

在第三拍中，由于 rB 要在第四拍结束后才能完成加载，现在执行 Add 指令没有意义（第四拍会取到无意义的 rB 数字），因此插入一个 NOOP 指令空过一拍，等到 rB 加载完成

> 此处存在上一章节提到的所谓「数据冲突」：对寄存器的写后读冲突。在 rB 完成写入（D阶段）之前，ADD 指令不可以执行 E 阶段（取操作数+执行），否则会得到无意义的数据。

**四段流水线**

将 E 阶段分为两个子阶段：E1 和 E2。

这种情况下，在第三拍和第四拍，需要连续添加两个 NOOP 指令才能防止取到没读入的 rB 值。

虽然看似耗时 11 拍，多于三阶段流水线的 8 拍，但是四阶段每一拍的长度都更短，因此其花费的时间未必更长。

![image-20211119105438478](https://raw.githubusercontent.com/yijunquan-afk/img-bed-1/main/img2/1695704529.png)

NOOP：编译器加的，没有作用，占用一拍，防止数据冲突或不相关的指令执行。

### 流水线优化

#### 延迟转移

转移指令只有在执行后才能产生具体的影响

可以在转移指令取指之后执行结果出来之前，安排一条或几条不相关的但结果肯定有用的指令进入流水线执行，代替简单的 NOOP 空操作（上面使用的） --- 乱序执行

加在转移指令后，用来减小转移损失的这些指令称为 **延迟槽 delay slot**

这是一种解决控制冲突的方法。

#### 延迟加载

在某个操作数没有从内存中加载完成前，插入 NOOP 指令/空掉一拍/或者插入些其他有用的指令，使得使用了该操作数的指令延迟到操作数取完后再执行。

比如上面三阶段流水线在 Load rB<-M 后，加入 NOOP 指令，防止 ADD 指令取到没完成加载的 rB。

这本质上是用于解决数据冲突的方法。

下图表示了一条指令的源码，使用 NOOP 防止跳转时出现页错误的指令，和真正最快且没错的指令之前的对比。最快指令把前面的 101 ADD 指令放到了 JUMP 后边作为延迟槽，导致ADD 操作正好与 JUMP 并行，且正好在 STORE 前完成，没有错误。

![](https://raw.githubusercontent.com/yijunquan-afk/img-bed-1/main/img2/1695704530.png)

#### 循环展开

对于循环，每一次循环都需要判断一次条件，因此会出现很多条件转移。流水线痛恨这种有条件转移，因此需要想办法减少条件转移的数量。

循环展开：把一个循环的循环体复制若干次，其次数被称为展开因子（u），从而以步长u来执行循环，而不是 1。

每次执行 u 次后，判断循环是否结束的过晚，如果是则恢复中间步骤的结果。

提高性能的方式

> 降低循环开销
>
> 通过提高流水线性能提高并行性
>
> 提高寄存器、数据高速缓存或TLB的局部性

重点：大寄存器组的使用（寄存器窗口），RISC 流水线的三大优化方法，使用图