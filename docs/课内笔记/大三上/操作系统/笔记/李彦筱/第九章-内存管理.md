

# 第九章 内存管理

> 易俊泉学长原始笔记的链接如下：
>
> [第九章-内存管理](docs/课内笔记/大三上/操作系统/笔记/易俊泉/第九章-内存管理.md)

## 9.1 Background（背景）

![image-20211028142501840](https://raw.githubusercontent.com/yijunquan-afk/img-bed-1/main/img/image-20211028142501840.png)

程序必须放入内存。形成一个进程才能被执行

输入队列（作业队列）：磁盘上等待进入内存并执行的进程的集合

用户程序在执行前必须经历很多步骤

- 首先，经过编译程序将源代码编译成若干个目标模块
- 其次通过链接程序将编译好的目标模块以及所需的库函数链接在一起，形成完整的装入模块
- 最后通过装入程序将这些装入模块装入内存并执行					

![image-20211028142927540](https://raw.githubusercontent.com/yijunquan-afk/img-bed-1/main/img/image-20211028142927540.png)

但是，编译时，编译器如何确定各个变量实际在内存中的地址呢？

![image-20211028143020575](https://raw.githubusercontent.com/yijunquan-afk/img-bed-1/main/img/image-20211028143020575.png)

从上图中可以看出，编译时，R1 的逻辑地址空间可能是 200；但是，执行时，由于程序不可能被装入到 0 地址（0 地址有中断服务程序），因此实际地址不在 200，如果地址写死在了程序中，访问 200 地址时就会发生段错误。

:warning: **指令和数据绑定到内存地址可以在三个不同的阶段发生**

> 绑定：确定操作数存储的内存地址

> 编译时期 Compile time：如果内存位置已知，可生成绝对代码；如果开始位置改变，需要重新编译代码。这种方法仅在单道环境下适用，多道环境下无法预知进程分配到的地址空间位置。
>
> 装入时期 Load time：如果存储位置在编译时不知道，则必须生成可重定位代码，在装入内存时确定内存地址
>
> **执行时期 Execution time**：如果进程在执行时可以在内存中移动，则地址绑定要延迟到运行时。**需要硬件对地址映射的支持**，例如基址和限长寄存器

示例如下：

![image-20211028143731772](https://raw.githubusercontent.com/yijunquan-afk/img-bed-1/main/img/image-20211028143731772.png)

第一种：编译时修改绑定地址位置

第二种：装入内存时，更改程序中记录的绑定地址

第三种：程序中保持逻辑地址不变，执行到对应语句时，对地址做变换，计算出实际地址

### 逻辑与物理地址空间

**逻辑地址**：由 CPU 产生，也叫做虚拟地址（程序执行时 CPU 看到的地址）

**物理地址**：内存设备所读入的地址（真实的地址）

在**编译时期和装入时期**进行地址绑定，生成的逻辑地址和物理地址是**相同的**，而在**执行时的地址绑定策略是不同的**。

> 上方图片中，程序中记录的地址（内存中存放的地址）永远是逻辑地址（不管是编译/装入/执行期绑定）。前两种情况下（装入/编译期间），逻辑地址和物理地址相同；在执行期绑定时，逻辑地址不等于物理地址
>
> 这是因为程序中记录的地址就是 CPU 看到的地址，因此一定是虚拟地址。

**【概念】地址重定位**：将程序装入到与其地址空间不一致的物理空间，所引起的一系列地址变换过程。

> **静态地址重定位**
>
> > 在装入一个作业时，把作业中的指令地址全部转换为绝对地址,在作业执行过程中就无须再进行地址转换工作。
>
> 即在装入时进行地址绑定
>
> **动态地址重定位**
>
> > 动态地址重地位是在程序执行过程中，在 CPU 访问内存之前,将要访问的程序或数据地址转换成内存地址. 动态重定位依靠硬件地址变换机构完成。
>
> 即在执行时进行地址绑定
>
> 如果在编译时进行地址绑定的话，根本就不需要进行地址重定位。

![image-20211028144653501](https://raw.githubusercontent.com/yijunquan-afk/img-bed-1/main/img/image-20211028144653501.png)

左侧图片在装入时重定位，右侧图片在运行时，访问内存前进行重定位（通过将逻辑地址和基地址寄存器记录的 当前程序开始地址 相加）

用户程序所对应到的是逻辑地址，**物理地址对它从来都不可见**。

基地址寄存器又被称为重定位计数器，在硬件上，使用 MMU（Memory-Management Unit，内存管理部件）实现。MMU 负责把虚拟地址映射到物理地址，通过在访问内存前，把逻辑地址和基地址寄存器记录的地址相加实现映射。

> 操作系统的物理地址对用户程序是透明的。
>
> 多个用户程序可以包含相同的逻辑地址；操作系统会通过地址重定位将它们映射到不同的逻辑地址。

### 动态加载

动态加载可以节约内存空间

采用动态加载时，一个程序会被分为不同模块，每个模块只有在调用时才会加载。能达到更好的内存空间利用率。适用于包含大量处理罕见情况代码的程序。动态加载不需要操作系统的特别支持，通过程序员的程序设计实现。

### 动态链接

链接操作被推迟到执行时期进行。和动态加载不同，动态链接需要操作系统支持。

使用动态链接时，程序中包含小的代码片（存根），存根保存了如何找到需要的库程序。当调用到这部分程序时，存根被动态的替换为实际要链接到的程序。

操作系统的支持：操作系统需要检查例程是否在进程的内存空间。

> GNU/Linux 系统下的 .so 文件就是动态链接库

### 覆盖

用于内存很小的计算机的程序解决方案。

覆盖是指在内存中只包含当前需要运行的程序和数据。当需要其他部分程序时，从磁盘中动态加载，并替换当前内存中的程序。覆盖由用户执行，不需要操作系统的特别支持，覆盖结构的程序设计很复杂。

这是一种早期的主存扩容方式，在主存容量大大增加的今天几乎用不到了。

## 9.2 Swapping （交换）

交换也是一种解决主存大小不足的方式。

一个进程可以暂时被交换到**内存外的一个备份区**，随后可以被换回内存继续执行。

备份区是一个固定的足够大的可以容纳所有用户内存映像的拷贝（一般在磁盘上）；可以提供对这些内存映像的直接存取。

交换是由操作系统控制，利用外存空间（进程交换区），通过对进程实体的整体交换，来满足用户进程的内存需要。它的主要特点是**打破了进程运行的驻留性**

滚入，滚出——交换由于基于优先级的算法而不同，低优先级的进程被换出，这样高优先级的进程可以被装入和执行。

交换时间的**主要部分是转移时间**，总的转移时间直接同交换的内存的数量成比例。

换出又换入的进程放入的位置取决于地址绑定的策略：

如果进程使用静态重定位，那么换入时必须放到换出前的位置，否则会无法访问正确的地址。如果进程使用动态重定位，那么换入时可以放到内存中的其他位置。

如果一个进程正在等待 I/O 结束，一般不允许其被换出。这是因为如果 I/O 完成后进程仍未被换入， I/O 的结果将无法存储到正确的内存中。或者，可以让操作系统转交 I/O 的结果，这样就可以换出 I/O 中的进程了。

## 9.3 存储管理方式

### Contiguous Allocation（连续分配）

连续分配方式：为一个程序分配一段连续的内存空间，包括单一方式和多分区方式

#### 单一连续分配

单一连续分配类似于单道批处理系统中的分配方式：内存中仅保存一个用户作业。

主存通常被分为两部分：其中一个存储区域固定地分配给操作系统使用，通常放在低地址部分；另一个存储区域给用户程序使用，在高地址端。

用户区只能容纳一道作业

使用基址寄存器策略由来保护用户进程（同其他进程和改变的操作系统代码和数据分开

> 基址寄存器包含最小物理地址的值；限长寄存器包含逻辑地址的范围，每个逻辑地址必须比限长寄存器的值小。进行逻辑地址-物理地址的转换时，将逻辑地址加上基址寄存器的值即可得到物理地址。

![image-20211222144348943](https://raw.githubusercontent.com/yijunquan-afk/img-bed-1/main/img/image-20211222144348943.png)

下图展示了如何判断单一连续分配中地址是否在界限内。先检查逻辑地址是否 >0 且 <限长寄存器的值，如果满足，则由逻辑地址 + 基址寄存器值得到物理地址，并访问内存。

![image-20211028151550039](https://raw.githubusercontent.com/yijunquan-afk/img-bed-1/main/img/image-20211028151550039.png)      

适用于单道程序，存储利用率非常低下。

#### 多分区分配 Fixed Partitioning

多分区分配就是把内存分割为多个部分，每个进程占用一部分内存。这种分配可以实现进程的并行。

:star: **内碎片：一个分区被进程占用后剩下多余的部分；外碎片：无法被任何一个进程占用的小分区**

##### 固定分区分配（静态）

固定式分区是在作业装入之前，内存就被划分成若干个固定大小的连续分区。划分工作可以由系统管理员完成，也可以由操作系统实现。

> 固定分区的大小可以全部相同，也可以各不相同。不过，分区都是预先划定的，不可能动态分配一块分区。

一旦划分完成，在系统运行期间不再重新划分，即分区的个数不可变，分区的大小不可变，所以，固定式分区又称为**静态分区**。

划分分区的方法如下：

> 分区大小相等：只适用于多个相同程序的并发执行（处理多个类型相同的对象），缺乏灵活性。
>
> 分区大小不等：多个小分区、适量的中等分区、少量的大分区。根据程序的大小，分配当前空闲的、适当大小的分区。
>
> 不管怎么划分，地址空间的大小都是预先确定的，无法动态划分一块内存空间。

![image-20211028151941993](https://raw.githubusercontent.com/yijunquan-afk/img-bed-1/main/img/image-20211028151941993.png)

一般将内存的用户区域划分成大小不等的分区，可适应不同大小的作业的需要。系统有一张**分区说明表**，记录内存的分配情况。每个表目说明一个分区的大小、起始地址和是否已分配标志。分区说明表和内存分配图如下所示

![image-20211028152043164](https://raw.githubusercontent.com/yijunquan-afk/img-bed-1/main/img/image-20211028152043164.png)

**优点**：**易于实现，开销小。**

**缺点**：

分区大小固定: 内碎片问题（进程占用空间小于分区的空间时，分区多余的空间就被浪费了）

分区总数固定: 限制并发执行的进程数目。

管理采用的数据结构：分区表——记录分区的大小和使用情况

##### 可变分区分配（动态）

**分区的划分是动态的，不是预先确定的**。不同大小的分区分布在整个内存中。适用于多道程序。程序进入内存时，根据程序需要的内存空间大小，动态的分配不同大小的分区。

分区分配算法：寻找某个空闲分区，其大小需大于或等于程序的要求。若是大于要求，则将该分区分割成两个分区，其中一个分区为要求的大小并标记为“占用”，而另一个分区为余下部分标记为“空闲”。分区的先后次序通常是从内存低端到高端。

问题：外碎片。分区使用空间时，可能导致内存中出现「碎片」：部分空闲空间太短，以至于任何进程都无法使用它。

分区释放算法：需要将相邻的空闲分区合并成一个空闲分区。(这时要解决的问题是：合并条件的判断)

:question:如何从一个空的分区序列中满足一个申请需要？存在三种算法，决定如何将进程放入内存中：

> 首次适应：最先找到的
>
> 最佳适应：适应的最小的
>
> 最差适应：选择目前剩余空闲分区中最大的

首次适应算法 First Fit

把当前程序分配到第一块能放下所需进程的空间中。

分配可以从内存低端/高端开始

> 分配和释放的时间性能较好，可以在内存高地址端保留较大的内存空间
>
> 随着低端分区不断划分而产生较多小分区，每次分配时查找时间开销会增大。
>
> 随着运行时间的增加，内存中必定会出现一些不连续的小的空闲区，称为**外碎片**。虽然可能所有碎片的总和超过某一个作业的要求，但是由于不连续而无法分配。

**最佳适应算法Best Fit**

选择全部空闲空间中，满足作业要求，且大小最小的空闲分区。

> 为提高查找效率，空闲分区表（空闲区链）中的空闲分区要按从小到大进行排序，自表头开始查找到第一个满足要求的自由分区分配
>
> 最佳适应算法会产生最多的外碎片，而且外碎片会越来越小，几乎不能利用。

在两种分配算法中，解决碎片的方法是**拼接（或称紧缩）**（Compaction），即向一个方向（例如向低地址端）移动已分配的作业，使那些零散的小空闲区在另一方向连成一片。**动态重定位时才能用拼接**（否则访问内存会出问题）

最差分配算法：

选择全部空闲空间中，最大的一块分配给进程。不容易产生无法利用的外碎片，但是会快速耗尽大块的空闲空间，导致无法装入大型进程。

### External fragmentation（外碎片） 与Internal fragmentation（内碎片）

内碎片指的是已经分配给作业，但是由于作业占用不大，没有被利用的内存空间，外部碎片是指系统中还没有分配给作业的部分空间，它们由于碎片太小而无法分配给申请内存空间的新进程的存储块。

静态分区产生内碎片，动态分配产生外碎片。单一连续分配根本没有碎片的概念（因为内存中就一个进程）

外碎片的产生本质上是因为剩余的内存空间每块都太小，不足以放下一整个进程，而进程又必须连续的存放在内存中。如果允许进程离散的存放在内存中，就可以解决此问题了。

除了**拼接**之外，**分页**也是解决存储碎片的一种方法，它可以避开连续性要求，允许进程的物理地址空间不连续。

## 9.4 Paging（分页）

分页是离散式存储进程的一种方式。其他离散式存储方式包含分段和段页式存储。

分页的实现方式：把物理内存分成大小固定的块，叫做**帧** frame，把逻辑地址空间也分为固定大小的块，叫做**页 **page。一页和一帧的大小相同。

由于内存按帧分配，不会出现外碎片的问题（每个剩余空间至少包含一帧），但可能出现内碎片（程序末端无法占满一整个帧）。不过，进程的内碎片大小不会超过一页，相对固定空间分配来说，已经极大的缓解了内碎片问题。

通过**建立页和帧的映射关系**，即建立一个页表，把逻辑地址转换为物理地址。

> 在前面连续分配时，逻辑地址-物理地址变换是通过重定位寄存器完成的。在离散分配中，需要通过页表存储页-帧的对应关系。
>
> 比如下图说明 0 页在 1 帧，1 号页在第 4 帧……。
>
> 这种对应方式显然属于动态重定位（逻辑地址和物理地址不同，逻辑地址以页为单位，物理地址以帧为单位）

![image-20211102161650090](https://raw.githubusercontent.com/yijunquan-afk/img-bed-1/main/img/image-20211102161650090.png)

CPU 负责将内存分帧/分页。逻辑地址分成两部分：页码 page number（p）和偏移 page offset（d）。页码作为页表的索引，页表包含每页所在物理内存的基地址，因此查页表得到基地址，加上偏移就形成了物理内存地址。

> 通常，我们会选择 2^n^ 作为一页的大小，这样可以简单的把地址划分为页数和偏移两部分，只需要取前几位/后几位就行了。

![image-20211102162636400](https://raw.githubusercontent.com/yijunquan-afk/img-bed-1/main/img/image-20211102162636400.png)

逻辑地址由硬件分成两部分（通过取后几位作为页内偏移，前几位作为页码）。页内偏移长度为 $log_2(一页的长度)$。

![image-20211102162658264](https://raw.githubusercontent.com/yijunquan-afk/img-bed-1/main/img/image-20211102162658264.png)

从逻辑地址到物理地址的具体转换方式如上图所示。

- 把逻辑地址分为页码（p）和页内偏移（d）两部分
- 查询分页表，得到页码（p）对应的内存帧号（f）
- 将内存帧号（f）和页内偏移（d）组合起来（相加），构成物理地址。

> 这里只是简单介绍地址变换方式，后面会详细介绍

### 地址结构

图中的地址长度为 32 位，允许地址空间的大小最多为 1M 个页。 

> 1M 页是 $2^{20}$，因此页号长度为 20，从而页内地址长度为 12。

![image-20211222145947266](https://raw.githubusercontent.com/yijunquan-afk/img-bed-1/main/img/image-20211222145947266.png)

程序经过编译链接后形成逻辑地址，对某特定机器其地址结构是一定的。若给定一个逻辑地址为A(十进制)，页面大小为 L，则页号P和页内地址W可按下式求得：

![image-20211222150012482](https://raw.githubusercontent.com/yijunquan-afk/img-bed-1/main/img/image-20211222150012482.png)

页表十分重要，它通常放在**主存**中，需要两个寄存器指明页表的位置：

**页表基址寄存器指向页表；页表限长寄存器表明页表的长度**。（就像限制连续分配内存空间大小的两个寄存器一样）

> 页表也可以放在寄存器中，但现在计算机的内存都很大，寄存器一般不够装下所有页表。

**在这个机制中，每一次的数据/指令存取需要两次内存存取，一次是存取页表，一次是存取数据**。这比直接访问耗费了更多的时间。不过，通过一个联想寄存器 TLB，可以解决两次存取的问题

### 联想寄存器 TLB

> TLB 用于解决页表放在内存时，需要访问内存两次才能取到数据的问题

TLB 是一个缓冲寄存器，类似 cache，访问速度快于内存。因此，如果 TLB 的命中率较高，就像 cache 对内存访问的加速一样，TLB 可以大大加速页表的访问。

联想寄存器存的是页号和帧号的对应关系（和页表一致）；**如果页码在联想寄存器中缓存，把帧号取出；否则访问内存，从内存的完整页表中取出帧号**

例如

> 假设检索联想存储器的时间为20ns，访问内存的时间为100ns，访问联想存储器的命中率为85%，则CPU存取一个数据的平均时间:（注意得到帧号后需要去内存取数据，因此一定需要 100ns）
>
> $T=0.85\times(100+20)+0.15\times(20+100+100)=135ns$
>
> 或者：$T = 100 + 20 + 0.15\times 100 = 135ns$
>
> 第二个算式的意思是：无论是否命中，都需要去 TLB 查询一次页表；无论是否命中，最终都需要访问内存读取数据，因此至少需要 120ns；此外，还有 15% 的概率未命中 TLB，需要访问内存中的页表，因此平均时间再增加 100*15%=15ns，即总共 135ns。

> 使用 TLB+页表 时，访问内存时间只增加 35%。如果不引入联想存储器，只使用页表，其访问时间将延长一倍（达200ns）。

### 地址变换机构

地址变换机构负责实现从逻辑地址到物理地址的转换：将用户程序中的页号变换成内存中的物理块号

地址变换机构是一个范围较大的概念，具体包含：

> 页表寄存器
>
> 有效地址寄存器（逻辑地址寄存器）
>
> 物理地址寄存器
>
> 页表
>
> PCB中增加存放页表始址和页表长度的项

###  地址变换过程

> 地址变换过程全部由硬件完成，不需要操作系统的主动介入

:one: 按页的大小分离出页号和位移量，放入有效地址寄存器中

:two: （有效性检查）将页号与页表长度进行比较，如果页号大于页表长度，地址越界，引发中断；

:three: （如果页号合法）以页号为索引查找页表：计算页表起始地址 + 页表项长度 * 页号，便得到该表项在页表中的位置，于是可从中得到该页的物理块号；

:four: 将该物理块号装入物理地址寄存器的高址部分；

:five: 将有效地址寄存器中的位移量直接复制到物理地址寄存器的低位部分，从而形成内存地址。

![image-20211102164315984](https://raw.githubusercontent.com/yijunquan-afk/img-bed-1/main/img/image-20211102164315984.png)![image-20211222150449183](https://raw.githubusercontent.com/yijunquan-afk/img-bed-1/main/img/image-20211222150449183.png)

虚地址（逻辑地址、程序地址）以十六进制、八进制、二进制的形式给出，转换为物理地址的步骤如下：

1. 先将虚地址转换成二进制的数；

2. 按页的大小分离出页号和位移量（低位部分是位移量，高位部分是页号）；

3. 将位移量直接复制到内存地址寄存器的低位部分；

4. 以页号查页表，得到对应页装入内存的块号，并将块号转换成二进制数填入地址寄存器的高位部分，从而形成内存地址。

虚地址以十进制数给出

> 页号＝虚地址％页大小
>
> 位移量＝虚地址 mod 页大小

1. 以页号查页表，得到对应页装入内存的块号

2. **内存地址＝块号×页大小（注意要乘页大小）＋位移量**

#### 举例

![image-20211102164752569](https://raw.githubusercontent.com/yijunquan-afk/img-bed-1/main/img/image-20211102164752569.png)

> 注意地址后面的「H」只是提醒你这是个 16 进制数，不是数字的一部分。
>
> 由于页大小为 2kb=$2^{11}$，低十一位是页内偏移，高位为页号

![image-20211102165010104](https://raw.githubusercontent.com/yijunquan-afk/img-bed-1/main/img/image-20211102165010104.png)

### 页的共享与保护

在分页存储管理系统中，实现共享的方法是使**共享用户地址空间中的页指向相同的物理块。**

在分页存储管理系统中实现共享比在分段系统中要困难。这是因为，分页存储管理系统中将作业的地址空间划分为页面的做法对用户是透明的，同时作业的地址空间是线性连续的，当系统将作业的地址空间分成大小相同的页面时，被共享的部分不一定包含在一个完整的页面中，这样不应该共享的数据也被共享了，不利于保密。另外，共享部分的起始地址在各作业的地址空间划分成页的过程中，在各自页面中的页内位移可能不同，这也会使共享比较困难。

分页存储管理系统可以为内存提供两种保护方式：**一种是地址越界保护；另一种是通过页表中的访问控制信息对内存信息提供保护**。

内存的保护由与每个页框相连的保护位来执行。

有效-无效位附在页表的每个表项中

> “有效”表明相关的页在进程的逻辑地址空间，以及是一个合法的页。
>
> “无效”表明页不在进程的逻辑地址空间中。

![image-20211102165311715](https://raw.githubusercontent.com/yijunquan-afk/img-bed-1/main/img/image-20211102165311715.png)

## 9.5 页表结构

### 两级页表

有的内存的逻辑地址有 $2^{32}B$（4 GB），假设每页大小为 4kb（$2^{12}$），则页表项有 1M （$2^{20}$）个。如果每个页表项占用 4B，那么页表就需要占用连续的 4M，这实在太大了：页表凭什么占掉连续的 1000 个页？

为了减少页表所占用的连续的内存空间，采用了两级页表机制。实际放在内存中的页表称为二级页表，记录离散的二级页表位置的页表称为一级页表。

**二级页表可以分为多个碎块存放，一级页表记录二级页表的各个碎块存放在内存的哪个位置（哪一帧）**

一级页表记录了二级页表位于内存的哪个物理帧（每一项都存放了某个二级页表部分的物理地址）；二级页表才记录了逻辑地址页具体对应哪个帧。

![image-20211102165847412](https://raw.githubusercontent.com/yijunquan-afk/img-bed-1/main/img/image-20211102165847412.png)

**二级页表是如何减少内存占用的呢？**

显然，如果只是单纯的划分二级页表，那么只是将一级页表分成了多个部分存放，并不能减少页表占用的内存空间。

如何解决这一问题呢？我们可以想到，**页表存储整个逻辑地址空间对应的物理内存帧**。现代计算机中，整个逻辑地址空间可能有 4GB（$2^{32}$，对 32 位应用程序）甚至更大（$2^{64}$），但是我们的程序真的需要这么大的内存空间吗？显然不需要，绝大多数人写的程序占用内存都不会超过 4GB，更别提 $2^{64}$ 那么大的空间了。

使用一级页表时，有的内存的逻辑地址有 $2^{32}B$（4 GB），假设每页大小为 4kb（$2^{12}$），则页表项有 1M （$2^{20}$）个。如果每个页表项占用 4B，那么页表就需要占用连续的 4M。

但是，使用二级页表时，我们**不需要为所有逻辑地址都分配一级页表**，只需要对真正使用的那段地址创建一级页表就行。如果某个虚拟地址范围从未使用，对应的二级页表根本不需要存在。

举例：如果进程只使用了 4GB 中的 1GB 的虚拟地址空间（假设页大小为 4KB），理论上只需要 $1\ \text{GB} / 4\ \text{KB} = 2^{18}$ 页表项，而不是为整个 4GB 虚拟地址空间分配。看，页表项数减少到了原先的 1/4，只需要 1M 就能存储了！

总结：

**总空间需求**：理论上，两级页表总占用的地址空间（虚拟页表的逻辑大小）和单级页表一样大。

**有效空间占用**：由于未使用的地址空间不会分配二级页表，两级页表的实际内存占用大大减少。

> 如果所有虚拟地址空间都被使用，两级页表和单级页表的内存占用是相同的。

**两级页表的地址划分**

在只有一级页表时，逻辑地址分为两部分：页表号和页内偏移。而现在，由于多了一级页表，逻辑地址被分成三部分：**外部页表、内部页表、偏移**

![image-20211102170115842](https://raw.githubusercontent.com/yijunquan-afk/img-bed-1/main/img/image-20211102170115842.png)

> 由于每一级都分开的以表的形式存储在内存中，把一个逻辑地址转换为一个物理地址要进行 **3 次**内存存取。先从内存中找到一级页表的位置，根据一级页表的记录找到二级页表的地址，再根据二级页表存储的地址找到实际帧
>
> 二级页表需要 3 次访问，三级页表需要 4 次访问……一般最多分为 7 级页表，不然访问时间太长了
>
> 尽管每次内存存取的时间是很大的，高速缓存使执行的时间还是可以接受的。

访问的时间增加，因为需要多次访问内存读取页表。

### 哈希页表

如果内存大小大于 4GB（32 位），那么分为两级页表后，搜索时间会很大；因此，可以引入哈希页表。

哈希页表利用哈希函数，计算逻辑地址的哈希值作为存储位置，将逻辑地址对应的物理地址存储在对应位置；查询时，计算页表号的哈希值，可以直接找到存储位置，只需 O（1）的时间。

哈希页表解决哈希冲突的方法是*开散列法*。如果两个逻辑地址的哈希值相同，它们会通过链表存储到同一位置，不会让某个逻辑地址重定位到后续的一个存储地址。

![image-20211102171917982](https://raw.githubusercontent.com/yijunquan-afk/img-bed-1/main/img/image-20211102171917982.png)

### 反转页表

通常的页表为每个进程设置一张页表（因为不同进程的逻辑地址可以重复，不能用一张页表存储），其不足之处是浪费内存空间

解决：引入**反转页表，按照整个物理内存建造一张表**

内存中的每一块在表中占一项。 

每项包含存储在当前帧物理内存的进程的逻辑页号和进程标示。

> 这种表之所以叫反转表，是因为一般的页表以逻辑地址作为表索引，物理地址作为存储内容；而反转表利用物理地址做索引，在每个表项中存储当前物理地址对应的逻辑地址，正好反过来了。

减少了页表占用的内存空间量,但是增加了查找表的时间，因为页表是按物理块的顺序组织的，而查找是按虚地址进行的，因此查找时可能需要遍历整个页表。 

可以使用哈希表来进一步减少搜索。

### 页表的内存共享

页表有利于简化内存共享：只需要确定进程中哪些页是可以共享的，然后在不同进程的页表中将这些页的逻辑地址映射到同一物理地址即可。比如：

![image-20241025103142161](/Users/liyanxiao/Documents/Xjtuse-Guide/docs/课内笔记/大三上/操作系统/笔记/李彦筱/./第九章-内存管理.assets/image-20241025103142161.png)

三个进程 P1，P2，P3 共享代码段 ed1, ed2, ed3（不同进程中，这三页的逻辑地址指向相同的物理地址，即指向 3、4、6）；不过，每个进程的 data 1/data2/data3 是相互独立的，指向不同的物理地址

### 纯分页特点

> 「不纯」的分页是后面讲到的虚拟内存

**优点**

> **内存利用率高、实现了离散分配、便于存储访问控制、无外部碎片**，内碎片不会超过一页的大小

**缺点**

> **需要硬件支持（地址转换和快表）、内存访问效率下降、共享困难、内部碎片**

## 9.6 Segmentation（分段）

分段是一种符合用户观点的内存管理机制。一般程序员在没学过分页前可能认为，程序是连续存放在内存中的，最多只能把栈/堆/静态区分成三部分存放。而分段就是按用户这种朴素想法设计的内存管理机制。

一个程序是一些段的集合，一个段是一个逻辑单位，如如下内容都可能是一个段：

>  main program,
>
>  procedure,
>
>  function,
>
>  local variables, global variables,
>
>  common block,
>
>  stack,
>
>  symbol table, arrays

一个逻辑地址是两个向量的集合：基地址+偏移。因此，段表也由类似的结构构成：

**段表：存储段号、段在内存的起始地址和段长**

>  页表是固定大小的，因此页表不用存储页长

![image-20211102174010450](https://raw.githubusercontent.com/yijunquan-afk/img-bed-1/main/img/image-20211102174010450.png)

由于段表在运行时进行逻辑地址-物理地址的变换，属于动态重定位

![image-20211102174309777](https://raw.githubusercontent.com/yijunquan-afk/img-bed-1/main/img/image-20211102174309777.png)

地址变换过程

> **将逻辑地址中的段号S与段表长度TL进行比较。若 S≥TL，访问越界；**
>
> **若未越界，则根据段表的始址和该段的段号，计算出该段对应段表项的位置，从段表中读出该段在内存中的起始地址；**
>
> **然后再检查段内位移d是否超过该段的段长SL。若超过，即 d≥SL，同样发出越界中断信号；**
>
> **若未越界，则将该段的基址与段内位移d相加，得到要访问的内存物理地址。**

![image-20211102174459913](https://raw.githubusercontent.com/yijunquan-afk/img-bed-1/main/img/image-20211102174459913.png)

分段本质上是一种动态内存分配（不同段的长度不同），因此会产生外碎片。

### 段的共享与保护（了解）

在分段存储管理系统中，分段的共享是通过使多个作业的段表中相应表项都指向被**共享段的同一个物理副本来实现的。**

在多道程序环境下，必须注意共享段中信息的保护问题。当一一个作业正从共享段中读取数据时，必须防止另一个作业修改此共享段中的数据。在当今大多数实现共享的系统中，程序被分成代码区和数据区。不能修改的代码称为纯代码或可重入代码，这样的代码和不能修改的数据是可以共享的，而可修改的程序和数据则不能共享。

与分页管理类似，分段管理的保护主要有两种:**地址越界保护和访问控制保护**。关于访问控制保护的实现方式前面已经介绍过，这里不再重复。而地址越界保护则是利用段表寄存器中的段表长度与逻辑地址中的段号进行比较，若段号大于段表长度，则产生越界中断;再利用段表项中的段长与逻辑地址中的段内位移进行比较，若段内位移大于段长，则会产生越界中断。不过在允许段动态增长的系统中，段内位移大于段长是允许的。为此，段表中应设置相应的增补位以指示该段是否允许动态增长。

### 分段的特点

程序通过分段(segmentation)划分为多个模块，如代码段、数据段、共享段。

- 可以分别编写和编译

- 可以针对不同类型的段采取不同的保护

- 可以按段为单位来进行共享，包括通过动态链接进行代码共享
- 符合用户对程序内存分布的想法

**特点**：

- **没有内碎片，外碎片可以通过内存紧缩来消除。**

- 便于改变进程占用空间的大小。

- 进程需要全部装入内存，不支持部分装入

### 分段与分页的比较

|              |                            分 页                             | 分 段                                                        |
| ------------ | :----------------------------------------------------------: | :----------------------------------------------------------- |
| 目的         |                    为了提高内存的利用率；                    | 为了能更好地满足用户的需要。                                 |
| 单位划分     |  **页是信息的物理单位，页的大小是固定的，而且由系统确定。**  | 段是**信息的逻辑单位**,它含有一组意义相对完整的信息。段的长度是不固定的，取决于用户所编写的程序，并由编译程序来划分。 |
| 作业地址空间 |                      单一的线性地址空间                      | 二维的，标识一个地址需给出段名和段内地址（段内偏移）         |
| 内存分配     | 以页为单位离散分配，无外碎片，所以也无紧缩问题，不过有不超过一页的内碎片 | 以段为单位离散分配，类同可变分区，会产生许多分散的小自由分区——外碎片，造成主存利用率低，需采用紧缩解决碎片问题，但紧缩需花费时间 |
| 用户可见性   |                          对用户透明                          | 每段的长度需要编译器指定                                     |

分段类似于连续分配中的动态分区分配，其区别在于：分段将程序分为几个小段，每个小段间可以不连续；动态分区分配要为整个程序分配连续的空间，不能拆分为多段分配。

## 9.7 Segmentation with Paging（段页式）

「段页式」管理就是对内存既分段，又分页；既符合了用户对内存分配的想法，还避免了外碎片。

既具有分页系统能有效地**提高内存利用率**的优点，又具有分段系统能很好地**满足用户需要**的长处，是一种有效的存储管理方式。

### 基本原理

分页：将整个主存划分成大小相等的物理块（页框）

分段：把用户程序按程序的逻辑关系分为若干个段，并为每个段赋予一个段名；再把每个段划分成若干页，以帧为单位离散存放在内存中。

即**先分段，再分页**。

在段页式分配中，地址结构由**段号、段内页号和页内地址**三部分组成

![image-20211102175943286](https://raw.githubusercontent.com/yijunquan-afk/img-bed-1/main/img/image-20211102175943286.png)

段号表示当前地址属于哪个段，页号表示当前地址属于段内的哪个页，页内地址就是每页内的偏移。

为了实现从逻辑地址到物理地址的变换，系统中需同时配置**段表和页表**。

由于将段中的页进行离散地分配，段表中的内容**不再是段的内存始址和段长**，而是**页表始址和页表长度**。 

页表的内容没有变化，仍然保存逻辑地址到物理帧的对应关系。

段表存储的内容如下：

![image-20211102180035741](https://raw.githubusercontent.com/yijunquan-afk/img-bed-1/main/img/image-20211102180035741.png)

在段页式中，进行逻辑-物理地址变换的方法如下：

![image-20211109210930145](https://raw.githubusercontent.com/yijunquan-afk/img-bed-1/main/img/image-20211109210930145.png)

段页式的重点就是**注意段表存储的内容发生了变化**。

### 地址变换过程

> 将段号S与段表长度TL进行比较
>
> 若S＜TL，表示未越界，于是利用段表始址和段号求出该段对应的段表项在段表中的位置，从中得到该段的页表始址与页表长度
>
> 将逻辑地址中的段内页号P与页表长度PL进行比较:若P＜PL，则用页号来获得对应页的页表项位置，从中读出该页所在的物理块号b
>
> 用块号 b和页内地址构成物理地址

在段页式系统中，为了获取一条指令或数据，需**三次访问内存**。

- 第一次是访问内存中的段表，从中取得所需页表始址

- 第二次是访问内存中的页表，从中取得物理块号，并将该块号与页内地址一起形成物理地址

- 第三次才是真正从第二次访问所得到的物理地址中，取得指令或数据。

### 优点和缺点

段页式解决了段式分配导致存在外碎片的问题。不过，由于段末尾可能不能完全占用一页，又出现了内碎片的问题……
